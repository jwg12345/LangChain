{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 환경설정"
      ],
      "metadata": {
        "id": "YJM11xQ_qWWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ttQhY7GjOOji",
        "outputId": "e4f6970f-3234-45e3-ca06-a067f60e3a09"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.2.7)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (2.16.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.6.6)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain_openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-1.1.7\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.2.7)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-text-splitters-1.1.0 langchain_community-0.4.1 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "dTxPYf8IRefE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Langchain 제공 기능"
      ],
      "metadata": {
        "id": "vyTg2PGOqbsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고 자료 : https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/"
      ],
      "metadata": {
        "id": "AItlxxNmRLeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Message passing\n",
        "- 이전 대화 내용을 chain에 넘겨주는 것\n",
        "\n",
        "- The simplest form of memory is simply passing chat history messages into a chain."
      ],
      "metadata": {
        "id": "N5XYv0azqf3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4o\") # gpt-3.5-turbo-0125"
      ],
      "metadata": {
        "id": "bnr2xJAmRM5z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. YOU MUST ANSWER IN KOREAN.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "ai_msg = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\n",
        "                \"human\",\n",
        "                \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\",\n",
        "            ),\n",
        "            (\"ai\",  \"いただきます (이타다키마스)\"),\n",
        "            (\"human\", \"내가 방금 뭐라고 했지?\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mphlBET1RY8U",
        "outputId": "6cc19b6c-6c67-4d46-ee73-caf5021b0b72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신은 \"잘 먹겠습니다.\"를 일본어로 어떻게 말하는지 물었고, 저는 \"いただきます\" (이타다키마스)라고 대답했습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_msg = chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            (\n",
        "                \"human\",\n",
        "                \"내 이름은 jwg이고, AI를 공부하고 있어.\",\n",
        "            ),\n",
        "            (\"ai\",  \"그렇군요. 흥미로운데요?\"),\n",
        "            (\"human\", \"내 이름이 뭐라고?\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-nxFkBPTnL_",
        "outputId": "7ff5ab95-8324-4e6a-af42-bd0a6db7b449"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신의 이름은 jwg입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 응용 : 대화 쌓일 때마다 히스토리 저장하도록 구현"
      ],
      "metadata": {
        "id": "uzZlHV2vMP5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_list = []\n",
        "while(True):\n",
        "    user_input = input()\n",
        "    if user_input == \"종료\": break\n",
        "    history_list.append(\n",
        "        (\n",
        "            \"human\",\n",
        "            user_input,\n",
        "        )\n",
        "    )\n",
        "    print(\"## CHAT_HISTORY ##\")\n",
        "    print(history_list, \"\\n\")\n",
        "    ai_msg = chain.invoke(\n",
        "        {\n",
        "            \"messages\": history_list,\n",
        "        }\n",
        "    )\n",
        "    print(\"AI Says : \",ai_msg.content)\n",
        "\n",
        "    history_list.append(\n",
        "        (\n",
        "            \"ai\",\n",
        "            ai_msg.content,\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnGLhdn1LxJI",
        "outputId": "04e6c978-289b-463e-a0bc-b09e64d91534"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕')] \n",
            "\n",
            "AI Says :  안녕하세요! 어떻게 도와드릴까요?\n",
            "나는 고기를 좋아해\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '나는 고기를 좋아해')] \n",
            "\n",
            "AI Says :  고기를 좋아하시는군요! 어떤 종류의 고기를 가장 좋아하시나요? 소고기, 돼지고기, 닭고기 등 다양한 종류가 있는데요.\n",
            "돼지고기\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '나는 고기를 좋아해'), ('ai', '고기를 좋아하시는군요! 어떤 종류의 고기를 가장 좋아하시나요? 소고기, 돼지고기, 닭고기 등 다양한 종류가 있는데요.'), ('human', '돼지고기')] \n",
            "\n",
            "AI Says :  돼지고기를 좋아하시는군요! 돼지고기로는 삼겹살이나 갈비, 혹은 제육볶음 등 여러 맛있는 요리가 있죠. 혹시 특별히 좋아하는 돼지고기 요리가 있나요?\n",
            "부위 추천해줘\n",
            "## CHAT_HISTORY ##\n",
            "[('human', '안녕'), ('ai', '안녕하세요! 어떻게 도와드릴까요?'), ('human', '나는 고기를 좋아해'), ('ai', '고기를 좋아하시는군요! 어떤 종류의 고기를 가장 좋아하시나요? 소고기, 돼지고기, 닭고기 등 다양한 종류가 있는데요.'), ('human', '돼지고기'), ('ai', '돼지고기를 좋아하시는군요! 돼지고기로는 삼겹살이나 갈비, 혹은 제육볶음 등 여러 맛있는 요리가 있죠. 혹시 특별히 좋아하는 돼지고기 요리가 있나요?'), ('human', '부위 추천해줘')] \n",
            "\n",
            "AI Says :  돼지고기의 다양한 부위 중 몇 가지 추천해드리자면:\n",
            "\n",
            "1. **삼겹살**: 한국에서 가장 인기 있는 부위로, 구워 먹기 좋습니다. 지방과 살코기가 적절히 섞여 있어 부드럽고 맛있습니다.\n",
            "\n",
            "2. **목살**: 삼겹살보다 지방이 적고 살코기가 많아 쫄깃한 식감을 즐길 수 있습니다. 구이나 제육볶음에 잘 어울립니다.\n",
            "\n",
            "3. **안심**: 지방이 거의 없고 부드러운 식감을 자랑합니다. 스테이크나 돈까스로 먹기 좋습니다.\n",
            "\n",
            "4. **등심**: 안심과 비슷하게 부드럽지만 지방이 적절히 있어 고소한 맛이 나는 부위입니다. 구이뿐 아니라 탕수육이나 돈까스로도 좋습니다.\n",
            "\n",
            "5. **갈비**: 양념에 재워 구워 먹거나, 갈비탕으로 끓여 먹기 좋습니다. 달콤하고 짭조름한 양념이 잘 배어들어 맛있습니다.\n",
            "\n",
            "각 부위마다 고유의 맛과 식감이 있으니, 다양한 요리에 도전해 보시는 것도 좋을 것 같습니다!\n",
            "종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Chat history\n",
        "- ChatMessageHistory() 클래스 사용하기\n",
        "- It's perfectly fine to store and pass messages directly as an array, but we can use LangChain's built-in message history class to store and load messages as well."
      ],
      "metadata": {
        "id": "lHsjha-JTVMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://api.python.langchain.com/en/latest/chat_message_histories/langchain_community.chat_message_histories.in_memory.ChatMessageHistory.html"
      ],
      "metadata": {
        "id": "4EZYo9IoXgMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "chat_history.add_user_message(\n",
        "    \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\"\n",
        ")\n",
        "\n",
        "chat_history.add_ai_message(\"いただきます (이타다키마스)\")\n",
        "\n",
        "chat_history.messages\n",
        "# chat_history.clear()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82OuUOtETIpI",
        "outputId": "ff45e65f-e399-4e29-a9e1-57c04556ade4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='いただきます (이타다키마스)', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대화내용 바로바로 저장하기"
      ],
      "metadata": {
        "id": "dLOjjo9sWKdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "################ USER INPUT - 1 ################\n",
        "input1 = \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\"\n",
        "\n",
        "# 대화 히스토리에 입력(user_input) 저장\n",
        "chat_history.add_user_message(input1)\n",
        "print(\"첫번째 입력 후 history : \", chat_history.messages)\n",
        "\n",
        "################ AI RESPONSE - 1 ################\n",
        "# 답변 생성(response)\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": chat_history.messages,\n",
        "    }\n",
        ")\n",
        "\n",
        "# 대화 히스토리에 답변(response) 저장\n",
        "chat_history.add_ai_message(response)\n",
        "print(\"첫번째 답변 후 history : \", chat_history.messages)\n",
        "print()\n",
        "\n",
        "################ USER INPUT - 2 ################\n",
        "input2 = \"내가 방금 뭐라고 물어봤지?\"\n",
        "\n",
        "# 대화 히스토리에 입력(user_input) 저장\n",
        "chat_history.add_user_message(input2)\n",
        "print(\"두번째 입력 후 history : \", chat_history.messages)\n",
        "\n",
        "################ AI RESPONSE - 2 ################\n",
        "# 답변 생성(response)\n",
        "print(\"[두번째 입력에 대한 답변]\")\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"messages\": chat_history.messages,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0msG3hgTVvF",
        "outputId": "c130ef4b-2bbf-4bec-c1e9-49440c3f0fef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 입력 후 history :  [HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={})]\n",
            "첫번째 답변 후 history :  [HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={}), AIMessage(content='일본어로 \\'잘 먹겠습니다.\\'는 \"いただきます\"입니다. 한글 발음은 \"이다다키마스\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 59, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5PR4IHVJ3yV6eiycdOB8kTwhYsdA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c270e-78c2-77a2-bae6-40d051777d3d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 59, 'output_tokens': 31, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "두번째 입력 후 history :  [HumanMessage(content=\"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\", additional_kwargs={}, response_metadata={}), AIMessage(content='일본어로 \\'잘 먹겠습니다.\\'는 \"いただきます\"입니다. 한글 발음은 \"이다다키마스\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 59, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5PR4IHVJ3yV6eiycdOB8kTwhYsdA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c270e-78c2-77a2-bae6-40d051777d3d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 59, 'output_tokens': 31, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내가 방금 뭐라고 물어봤지?', additional_kwargs={}, response_metadata={})]\n",
            "[두번째 입력에 대한 답변]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"당신은 '잘 먹겠습니다.'를 일본어로 어떻게 말하는지 물어보셨습니다. 또한 한글 발음도 함께 요청하셨습니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 109, 'total_tokens': 143, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5PR5Vr1OJZiwCAu375aWDs8gG6NK', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c270e-7e61-74a0-bd1a-a30f5b4888fb-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 109, 'output_tokens': 34, 'total_tokens': 143, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 응용 : 대화 쌓일 때마다 히스토리 저장하도록 구현"
      ],
      "metadata": {
        "id": "8lNztnwgY5G3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "while(True):\n",
        "    user_input = input()\n",
        "    if user_input == \"종료\": break\n",
        "    chat_history.add_user_message(user_input)\n",
        "    response = chain.invoke(\n",
        "        {\n",
        "            \"messages\": chat_history.messages,\n",
        "        }\n",
        "    )\n",
        "    chat_history.add_ai_message(response)\n",
        "    print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atmi65POYM12",
        "outputId": "3c941cac-55a7-4189-828e-2a9c64b691b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕\n",
            "안녕하세요! 어떻게 도와드릴까요?\n",
            "배고파\n",
            "배고프시군요! 어떤 음식을 드시고 싶으신가요? 한국 음식이나 다른 종류의 음식을 추천해드릴 수도 있어요.\n",
            "한식으로 메뉴 추천좀\n",
            "물론이죠! 한식으로 다양한 메뉴가 있습니다. 몇 가지 추천드릴게요:\n",
            "\n",
            "1. **비빔밥** - 여러 가지 야채와 고기를 고추장 소스와 함께 비벼 먹는 요리입니다.\n",
            "2. **불고기** - 얇게 썬 소고기를 달콤하고 짭짤한 양념에 재워 구워 먹는 요리입니다.\n",
            "3. **김치찌개** - 김치와 돼지고기 또는 참치 등을 넣고 끓인 매콤하고 맛있는 찌개입니다.\n",
            "4. **떡볶이** - 떡과 어묵, 야채를 매콤한 고추장 소스에 볶아 만든 길거리 음식입니다.\n",
            "5. **삼겹살 구이** - 구운 삼겹살을 상추에 싸서 함께 먹는 인기 있는 고기 요리입니다.\n",
            "\n",
            "어떤 메뉴가 가장 끌리세요?\n",
            "종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Automatic history management\n",
        "- RunnableWithMessageHistory() 활용하여 메모리 관리하기\n",
        "- The previous examples pass messages to the chain explicitly. This is a completely acceptable approach, but it does require external management of new messages. LangChain also includes an wrapper for LCEL chains that can handle this process automatically called RunnableWithMessageHistory."
      ],
      "metadata": {
        "id": "h5IW96A8WNYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model=\"gpt-4o\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. YOU MUST ANSWER IN KOREAN.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat"
      ],
      "metadata": {
        "id": "ECXuHzfWWNol"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "chat_history_for_chain = ChatMessageHistory()\n",
        "\n",
        "chain_with_message_history = RunnableWithMessageHistory(\n",
        "    chain, # 실행할 Runnable 객체\n",
        "    lambda session_id: chat_history_for_chain, # 세션 기록을 가져오는 함수\n",
        "    input_messages_key=\"input\", # 입력 메시지의 Key\n",
        "    history_messages_key=\"chat_history\", # 대화 히스토리 메시지의 Key\n",
        ")"
      ],
      "metadata": {
        "id": "y2GV7xqWWPGk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_message_history.invoke(\n",
        "    {\"input\": \"일본어로 '잘 먹겠습니다.' 어떻게 말해? 한글 발음도 함께 말해줘.\"},\n",
        "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0QE2_qxWPkl",
        "outputId": "bdf88d24-8676-4c51-bcf2-9eb38182b175"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='일본어로 \\'잘 먹겠습니다\\'는 \"いただきます\"라고 말합니다. 한글 발음은 \"이타다키마스\"입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 59, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5PcK305oBaLvCyj3XzQfC9eMH7mC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2719-2262-7973-bb82-7677b59505b7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 59, 'output_tokens': 34, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_message_history.invoke(\n",
        "    {\"input\": \"내가 뭐라고 물어봤지?\"}, {\"configurable\": {\"session_id\": \"unused\"}}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5898B2zWRQT",
        "outputId": "1f451716-2138-40a5-eda4-2a52247dd69c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='당신은 \"\\'잘 먹겠습니다\\'를 일본어로 어떻게 말하는지\" 물어보셨습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 110, 'total_tokens': 133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5PdCKSIOfByqZFeqhHzVSsewcMQ4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2719-ef71-79e0-a941-3133a255f63d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 110, 'output_tokens': 23, 'total_tokens': 133, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "히스토리 저장 함수를 따로 호출할 필요없이 invoke 실행만으로 대화 기록이 자동 저장되는 것을 확인 가능!"
      ],
      "metadata": {
        "id": "mwFQUG_PgvGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Modifying chat history\n",
        "- 이전 대화 내용을 가공하여 넘겨주기\n",
        "- Modifying stored chat messages can help your chatbot handle a variety of situations."
      ],
      "metadata": {
        "id": "R9HtRAXzfutg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "chat_history.add_user_message(\"안녕하세요. 제 이름은 jwg입니다.\")\n",
        "chat_history.add_ai_message(\"안녕하세요, jwg님! 무엇을 도와드릴까요?\")\n",
        "chat_history.add_user_message(\"날씨 좋은 날 들을만 한 노래 추천해주세요.\")\n",
        "chat_history.add_ai_message(\"Carpenters - Close to you 를 추천해요.\")\n",
        "\n",
        "chat_history.messages\n",
        "# chat_history.clear()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJicGgSXWvkL",
        "outputId": "9993cafb-3739-4c76-8b43-42bbe2bb07c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='안녕하세요. 제 이름은 jwg입니다.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='안녕하세요, jwg님! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[]),\n",
              " HumanMessage(content='날씨 좋은 날 들을만 한 노래 추천해주세요.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Carpenters - Close to you 를 추천해요.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability. The provided chat history includes facts about the user you are speaking with. YOU MUST ANSWER IN KOREAN.\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "chain_with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    lambda session_id: chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "1f7vAPaCWyyE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def summarize_messages(chain_input):\n",
        "    stored_messages = chat_history.messages\n",
        "    if len(stored_messages) == 0:\n",
        "        return False\n",
        "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "            (\n",
        "                \"user\",\n",
        "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    summarization_chain = summarization_prompt | chat\n",
        "\n",
        "    # chat_history 에 저장된 대화 기록을 요약프롬프트에 입력 & 결과 저장\n",
        "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
        "\n",
        "    # chat_history 에 저장되어있던 기록 지우기\n",
        "    chat_history.clear()\n",
        "\n",
        "    # 생성된 새로운 요약내용으로 기록 채우기\n",
        "    chat_history.add_message(summary_message)\n",
        "\n",
        "    return True\n",
        "\n",
        "chain_with_summarization = (\n",
        "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
        "    | chain_with_message_history\n",
        ")"
      ],
      "metadata": {
        "id": "NEvcOsdqWzsZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- summarize_messages 함수의 실행 결과를 messages_summarized 라는 이름의 Key 로 저장\n",
        "\n",
        "    - 정의한 chain 안에 \"messages_summarized\" Key 가 정의되고 있지 않으므로, 이는 `summarize_messages` 함수를 실행하기 위한 무시 가능한 Key\n",
        "    - 함수가 실행되면 chat_history 에 요약된 히스토리가 저장됨\n"
      ],
      "metadata": {
        "id": "3Ed_Kcek8kvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_summarization.invoke(\n",
        "    {\"input\": \"제 이름을 기억하고 있나요?\"},\n",
        "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq4jhbBBW17O",
        "outputId": "2345831d-b247-4f19-eed3-9f449de8ad7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='죄송하지만, 대화 기록에서는 사용자의 이름이 언급되지 않았습니다. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 91, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5Pr4VH9wlvM90sbHI6UV5BwrnItn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2727-149c-7910-8152-1730ffe8d462-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 91, 'output_tokens': 25, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_summarization.invoke(\n",
        "    {\"input\": \"그 가수는 남자인가요 여자인가요?\"},\n",
        "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
        ")"
      ],
      "metadata": {
        "id": "XtwtUrBcW6eK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd850a4e-292e-4a62-ffcd-60e3bdf5d2ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The Carpenters는 남매 듀오로, 여성인 카렌 카펜터와 남성인 리처드 카펜터로 구성되어 있습니다. 카렌 카펜터가 주로 보컬을 맡았고, 리처드 카펜터는 주로 피아노 연주 및 작곡을 담당했습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 128, 'total_tokens': 202, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_fa7f5b168b', 'id': 'chatcmpl-D5PrODlPP1f04jMWB2mCfQIAPqjT3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2727-5f1b-7172-8de4-2505d7130760-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 128, 'output_tokens': 74, 'total_tokens': 202, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 끝말잇기 게임 구현하기\n",
        "\n",
        "- 4) Modifying chat history 의 활용!"
      ],
      "metadata": {
        "id": "Rn0LO7Bdr8nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 대화 기록을 저장할 히스토리 클래스 불러오기\n",
        "chat_history = ChatMessageHistory()\n",
        "\n",
        "# chat_history.add_user_message(\"끝말잇기 하자\")\n",
        "# chat_history.add_ai_message(\"좋습니다. 제가 먼저 시작할게요. 바나나!\")\n",
        "# chat_history.add_user_message(\"나이테\")\n",
        "# chat_history.add_ai_message(\"테이프\")\n",
        "\n",
        "chat_history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8709c45-f387-4641-e180-3e86fb41b140",
        "id": "OpnDi8ZFhx6y"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model=\"gpt-4o\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"당신은 끝말잇기 게임을 진행하는 AI 챗봇입니다. 아래는 게임 규칙입니다. 당신과 user 의 입력에서 아래 규칙이 꼭 지켜져야 하며, 지키지 않은 사람에게 패배를 알린 뒤, 끝말잇기 게임을 종료합니다.\n",
        "                1. 주어진 대화 기록에서 이미 나왔던 단어를 다시 말했을 경우 패배합니다.\n",
        "                2. 두음법칙을 허용합니다. (ex. 리 -> 이, 력 -> 역, 락 -> 낙)\n",
        "                3. 국어사전에 존재하는 단어이자, 명사여야 합니다.\n",
        "            \"\"\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "chain_with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    lambda session_id: chat_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "dQoRukC8hx6z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_messages(chain_input):\n",
        "    stored_messages = chat_history.messages\n",
        "    if len(stored_messages) == 0:\n",
        "        return False\n",
        "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"placeholder\", \"{chat_history}\"),\n",
        "            (\n",
        "                \"user\",\n",
        "                \"위 채팅 메시지는 끝말잇기 게임을 진행한 대화내용입니다. 언급한 단어들만 나열하여 저장해주세요.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    summarization_chain = summarization_prompt | chat\n",
        "\n",
        "    # chat_history 에 저장된 대화 기록을 요약프롬프트에 입력 & 결과 저장\n",
        "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
        "\n",
        "    # chat_history 에 저장되어있던 기록 지우기\n",
        "    chat_history.clear()\n",
        "\n",
        "    # 생성된 새로운 요약내용으로 기록 채우기\n",
        "    chat_history.add_message(summary_message)\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "chain_with_summarization = (\n",
        "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
        "    | chain_with_message_history\n",
        ")"
      ],
      "metadata": {
        "id": "BLMCkKMphx6z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "    user_input = input(\"🙋‍♂️ YOUR TURN : \")\n",
        "    if user_input == \"종료\": break\n",
        "    response = chain_with_summarization.invoke(\n",
        "                {\"input\": user_input},\n",
        "                {\"configurable\": {\"session_id\": \"unused\"}},\n",
        "            )\n",
        "    print(\"✍ AI TURN : \", response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDn2jJJGiw1a",
        "outputId": "fe0d2a20-cf68-43c2-9815-316f380ebde3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🙋‍♂️ YOUR TURN : 바보\n",
            "✍ AI TURN :  \"바보\"로 끝나는 단어를 시작하는 단어는 \"보\"입니다. \"보석\"을 제시합니다. 이제 \"석\"으로 시작하는 단어를 말씀해 주세요.\n",
            "🙋‍♂️ YOUR TURN : 석고\n",
            "✍ AI TURN :  고무\n",
            "🙋‍♂️ YOUR TURN : 무한\n",
            "✍ AI TURN :  한자\n",
            "🙋‍♂️ YOUR TURN : 자객\n",
            "✍ AI TURN :  객관\n",
            "🙋‍♂️ YOUR TURN : 관습\n",
            "✍ AI TURN :  습관\n",
            "🙋‍♂️ YOUR TURN : 관철\n",
            "✍ AI TURN :  철도\n",
            "🙋‍♂️ YOUR TURN : 도력\n",
            "✍ AI TURN :  력사\n",
            "\n",
            "(두음법칙에 의해 '역사'로도 시작할 수 있습니다.)\n",
            "🙋‍♂️ YOUR TURN : 사슴\n",
            "✍ AI TURN :  음료\n",
            "🙋‍♂️ YOUR TURN : 슴인데 어떻게 음료냐\n",
            "✍ AI TURN :  죄송합니다. 잘못된 연결이었습니다. 제가 패배했습니다. 끝말잇기 게임을 종료합니다. 추가로 도와드릴 것이 있으면 말씀해 주세요.\n",
            "🙋‍♂️ YOUR TURN : 종료\n"
          ]
        }
      ]
    }
  ]
}