{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LangGraph for making agentic systems\n",
        "- LangGraph는 LLM을 활용한 워크플로우를 구현하기 위한 프레임 워크\n",
        "- 시스템의 상태를 기반으로 동작하며 흐름을 그래프(노드-엣지)로 표현\n",
        "- 동적인 동작 제어와 관리를 통해 고도화된 Agentic Systems를 구현"
      ],
      "metadata": {
        "id": "IScXbHVjwhy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "yyLvIYgzH2YX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3d364d-b318-42d9-9c4a-4ac18c6bdd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/2.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.9/397.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU tavily-python langchain_community langchain_anthropic langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use Tavily Search API\n",
        "\n",
        "Tavily Search Documents : https://docs.tavily.com/docs/python-sdk/tavily-search/getting-started\n",
        "\n",
        "Get API Key : https://app.tavily.com/home"
      ],
      "metadata": {
        "id": "OGjd93BrMoUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-...\""
      ],
      "metadata": {
        "id": "EQnu3EWPIlGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tavily import TavilyClient\n",
        "\n",
        "tavily_client = TavilyClient()"
      ],
      "metadata": {
        "id": "gOI4lwdmcPvE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**search**\n",
        "\n",
        "- Return : dict with all related response fields"
      ],
      "metadata": {
        "id": "Mkbj0fXLcGj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = tavily_client.search(\"What is AI Agent?\", max_results=3) # , topic=\"news\", days = 10\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlJ7AYmqJIOD",
        "outputId": "373c4fe3-3d4a-4f7f-e12f-e0f7421eb430"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is AI Agent?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'content': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'score': 0.99987173, 'raw_content': None}, {'url': 'https://www.reddit.com/r/AI_Agents/comments/1kgruv2/what_even_is_an_ai_agent/', 'title': 'What even is an AI agent? : r/AI_Agents - Reddit', 'content': 'An AI agent is generally understood as a software system that can perform tasks autonomously by orchestrating multiple processing steps,', 'score': 0.99984396, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/AI_agent', 'title': 'AI agent - Wikipedia', 'content': '# AI agent. 9. ^ ***a*** ***b*** ***c*** ***d*** ***e*** ***f*** ***g*** ***h*** ***i*** ***j*** ***k*** \"AI Agents: The Next Generation of Artificial Intelligence\". ^ ***a*** ***b*** ***c*** \"What are the risks and benefits of \\'AI agents\\'?\". AI Agents Are the Future\". ^ ***a*** ***b*** ***c*** \"China is gaining ground in the global race to develop AI agents\". \"Which AI agent is the best? \"Why Everything\\'s an AI \\'Agent\\' Now\". ^ ***a*** ***b*** \"AI agents are coming for your privacy, warns Meredith Whittaker\". ^ ***a*** ***b*** \"AI agents: Exploring the potential and the problems\". \"What is an AI agent? ^ ***a*** ***b*** \"AI agents: Exploring the potential and the problems\". \"How Are Companies Using AI Agents? \"What Are AI \\'Agents\\' For?\". ^ ***a*** ***b*** ***c*** ***d*** ***e***  Banerjie, Shruti; Zhu, Yuxin; Freeman, Isaac; Machado, Julyssa Villa; Ahmed, Abdulaziz; Sarker, Abeed; Al-Garadi, Mohammed (November 5, 2025), *Agentic AI in Healthcare: A Comprehensive Survey of Foundations, Taxonomy, and Applications*, Preprints, doi \"Doi (identifier)\"):10.36227/techrxiv.176238073.31262603/v1, retrieved January 17, 2026.', 'score': 0.9997017, 'raw_content': None}], 'response_time': 0.64, 'request_id': '5084de1e-512b-433f-a6ea-1a0268780083'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response['results']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG0u6DpWafov",
        "outputId": "cee475e4-cd1b-41a9-f3d2-80ecb40977d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.ibm.com/think/topics/ai-agents',\n",
              "  'title': 'What Are AI Agents? | IBM',\n",
              "  'content': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.',\n",
              "  'score': 0.99987173,\n",
              "  'raw_content': None},\n",
              " {'url': 'https://www.reddit.com/r/AI_Agents/comments/1kgruv2/what_even_is_an_ai_agent/',\n",
              "  'title': 'What even is an AI agent? : r/AI_Agents - Reddit',\n",
              "  'content': 'An AI agent is generally understood as a software system that can perform tasks autonomously by orchestrating multiple processing steps,',\n",
              "  'score': 0.99984396,\n",
              "  'raw_content': None},\n",
              " {'url': 'https://en.wikipedia.org/wiki/AI_agent',\n",
              "  'title': 'AI agent - Wikipedia',\n",
              "  'content': '# AI agent. 9. ^ ***a*** ***b*** ***c*** ***d*** ***e*** ***f*** ***g*** ***h*** ***i*** ***j*** ***k*** \"AI Agents: The Next Generation of Artificial Intelligence\". ^ ***a*** ***b*** ***c*** \"What are the risks and benefits of \\'AI agents\\'?\". AI Agents Are the Future\". ^ ***a*** ***b*** ***c*** \"China is gaining ground in the global race to develop AI agents\". \"Which AI agent is the best? \"Why Everything\\'s an AI \\'Agent\\' Now\". ^ ***a*** ***b*** \"AI agents are coming for your privacy, warns Meredith Whittaker\". ^ ***a*** ***b*** \"AI agents: Exploring the potential and the problems\". \"What is an AI agent? ^ ***a*** ***b*** \"AI agents: Exploring the potential and the problems\". \"How Are Companies Using AI Agents? \"What Are AI \\'Agents\\' For?\". ^ ***a*** ***b*** ***c*** ***d*** ***e***  Banerjie, Shruti; Zhu, Yuxin; Freeman, Isaac; Machado, Julyssa Villa; Ahmed, Abdulaziz; Sarker, Abeed; Al-Garadi, Mohammed (November 5, 2025), *Agentic AI in Healthcare: A Comprehensive Survey of Foundations, Taxonomy, and Applications*, Preprints, doi \"Doi (identifier)\"):10.36227/techrxiv.176238073.31262603/v1, retrieved January 17, 2026.',\n",
              "  'score': 0.9997017,\n",
              "  'raw_content': None}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**get_search_context**\n",
        "\n",
        "- Return : str containing the content and sources of the results"
      ],
      "metadata": {
        "id": "t5XJ6b4NblxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = tavily_client.get_search_context(query=\"What is AI Agent?\")\n",
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl9O4x0rJVCr",
        "outputId": "292ee4be-3a24-4468-8621-3f37412a49fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3674300269.py:1: DeprecationWarning: get_search_context is deprecated and will be removed in future versions.\n",
            "  context = tavily_client.get_search_context(query=\"What is AI Agent?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"url\": \"https://www.ibm.com/think/topics/ai-agents\", \"content\": \"An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.\"}, {\"url\": \"https://aws.amazon.com/what-is/ai-agents/\", \"content\": \"# What are AI Agents? * How does an AI agent work? * What are the challenges of using AI agents? ## What are AI Agents? An artificial intelligence (AI) agent is a software program that can interact with its environment, collect data, and use that data to perform self-directed tasks that meet predetermined goals. While traditional software follows hard-coded instructions, AI agents identify the next appropriate action based on past data and execute it without continuous human oversight. AI agents interact with their environment by collecting data through sensors or digital inputs. The AI agent applies the data to make an informed decision. Business teams are more productive when they delegate repetitive tasks to AI agents. ## How does an AI agent work? AI agents work by simplifying and automating complex tasks. AI agents require information to execute tasks they have planned successfully. With sufficient data, the AI agent methodically implements the task at hand. ## What are the challenges of using AI agents?\"}, {\"url\": \"https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-an-ai-agent\", \"content\": \"AI agents are the tools we use to interact with AI. They can automate and perform complex tasks, such as natural language processing,\"}, {\"url\": \"https://www.bcg.com/capabilities/artificial-intelligence/ai-agents\", \"content\": \"AI agents are artificial intelligence that use tools to accomplish goals. AI agents have the ability to remember across tasks and changing states.\"}, {\"url\": \"https://www.reddit.com/r/AI_Agents/comments/1kgruv2/what_even_is_an_ai_agent/\", \"content\": \"An AI agent is generally understood as a software system that can perform tasks autonomously by orchestrating multiple processing steps,\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "zQ1tFnZPx13L",
        "outputId": "352dc3fe-a17c-4d27-ad26-5b992cfecdd3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[{\"url\": \"https://www.ibm.com/think/topics/ai-agents\", \"content\": \"An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.\"}, {\"url\": \"https://aws.amazon.com/what-is/ai-agents/\", \"content\": \"# What are AI Agents? * How does an AI agent work? * What are the challenges of using AI agents? ## What are AI Agents? An artificial intelligence (AI) agent is a software program that can interact with its environment, collect data, and use that data to perform self-directed tasks that meet predetermined goals. While traditional software follows hard-coded instructions, AI agents identify the next appropriate action based on past data and execute it without continuous human oversight. AI agents interact with their environment by collecting data through sensors or digital inputs. The AI agent applies the data to make an informed decision. Business teams are more productive when they delegate repetitive tasks to AI agents. ## How does an AI agent work? AI agents work by simplifying and automating complex tasks. AI agents require information to execute tasks they have planned successfully. With sufficient data, the AI agent methodically implements the task at hand. ## What are the challenges of using AI agents?\"}, {\"url\": \"https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-an-ai-agent\", \"content\": \"AI agents are the tools we use to interact with AI. They can automate and perform complex tasks, such as natural language processing,\"}, {\"url\": \"https://www.bcg.com/capabilities/artificial-intelligence/ai-agents\", \"content\": \"AI agents are artificial intelligence that use tools to accomplish goals. AI agents have the ability to remember across tasks and changing states.\"}, {\"url\": \"https://www.reddit.com/r/AI_Agents/comments/1kgruv2/what_even_is_an_ai_agent/\", \"content\": \"An AI agent is generally understood as a software system that can perform tasks autonomously by orchestrating multiple processing steps,\"}]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**qna_search**\n",
        "\n",
        "- Return : str, containing a short answer to the search query"
      ],
      "metadata": {
        "id": "Z-mPxePybb3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = tavily_client.qna_search(query=\"What is AI Agent?\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6F-UuixJenA",
        "outputId": "fd6e3a65-8b62-4f4c-c8a7-7208c467218f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1630415381.py:1: DeprecationWarning: qna_search is deprecated and will be removed in future versions.\n",
            "  answer = tavily_client.qna_search(query=\"What is AI Agent?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An AI agent is a software program that autonomously performs tasks, learns from experiences, and can interact with its environment to achieve goals. AI agents use advanced AI to automate complex workflows and make decisions independently. They can coordinate with other agents to solve problems efficiently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "id": "84pLENeabPV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4c2410bb-02ca-4157-cdae-8332bbf15ba2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'An AI agent is a software program that autonomously performs tasks, learns from experiences, and can interact with its environment to achieve goals. AI agents use advanced AI to automate complex workflows and make decisions independently. They can coordinate with other agents to solve problems efficiently.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use Tavily Search **as Tool** in Langchain\n",
        "\n",
        "- https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html\n",
        "\n",
        "- Tool that queries the Tavily Search API and gets back json"
      ],
      "metadata": {
        "id": "ZfZ8Af9oNIGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tool = TavilySearchResults(max_results=2) #웹 검색 tool\n",
        "tool.invoke(\"What's a 'node' in LangGraph?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRbawqsKIwrQ",
        "outputId": "b1995432-e389-4639-c30d-9d409631633d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1835957720.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  tool = TavilySearchResults(max_results=2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Understanding Core Concepts of LangGraph (Deep Dive)',\n",
              "  'url': 'https://dev.to/raunaklallala/understanding-core-concepts-of-langgraph-deep-dive-1d7h',\n",
              "  'content': '### 1. Nodes: The Execution Units\\n\\nA Node is basically “a single action.” Imagine breaking your workday into steps: checking email, making coffee, writing code, or scheduling a meeting. Each of those is a Node.\\n\\nIn LangGraph, a Node can be many things:\\n\\n A large language model call (like GPT, Gemini, or LLaMA).\\n A tool (search engine lookup, calculator, weather API, database query).\\n A custom function (Python function, regex cleaner, summarizer).\\n\\nEach Node is like a worker with a simple contract: it takes an input, does its piece of the job, and pushes out an output.\\n\\nEveryday example:  \\n  \\n Think about ordering food on a delivery app. [...] One Node takes your food order.\\n Another Node calls the restaurant’s system.\\n Another Node calculates delivery time. Each does one thing, and together they create your experience.\\n\\nAnalogy: Nodes are like “stations” on a metro map. The passenger (your data) steps off at every station, something happens to them, and then they move along.\\n\\n### 2.Edges: The Flow of Control\\n\\nNodes mean nothing without connections. That’s where Edges come in—they define how data flows between steps.\\n\\nThink of Edges as “decision pathways.” Sometimes they’re simple, sometimes they’re smart.\\n\\nTypes of edges:',\n",
              "  'score': 0.99998665},\n",
              " {'title': 'Graph API overview - Docs by LangChain',\n",
              "  'url': 'https://docs.langchain.com/oss/python/langgraph/graph-api',\n",
              "  'content': '\\u200b\\n\\nNodes\\n\\nIn LangGraph, nodes are Python functions (either synchronous or asynchronous) that accept the following arguments:\\n1.   `state` – The state of the graph\\n2.   `config` – A `RunnableConfig` object that contains configuration information like `thread_id` and tracing information like `tags`\\n3.   `runtime` – A `Runtime` object that contains runtime `context` and other information like `store` and `stream_writer`\\n\\nSimilar to `NetworkX`, you add these nodes to a graph using the `add_node` method:\\n\\nCopy\\n\\n```\\nfrom dataclasses import dataclass\\nfrom typing_extensions import TypedDict\\n\\nfrom langchain_core.runnables import RunnableConfig\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.runtime import Runtime\\n\\nclass State(TypedDict):\\n    input: str\\n    results: str [...] graph.add_edge(START, \"node_a\")\\n```\\n\\n### \\u200b\\n\\n`END` node\\n\\nThe `END` Node is a special node that represents a terminal node. This node is referenced when you want to denote which edges have no actions after they are done.\\n\\nCopy\\n\\n```\\nfrom langgraph.graph import END\\n\\ngraph.add_edge(\"node_a\", END)\\n```\\n\\n### \\u200b\\n\\nNode caching\\n\\nLangGraph supports caching of tasks/nodes based on the input to the node. To use caching:\\n   Specify a cache when compiling a graph (or specifying an entrypoint)\\n   Specify a cache policy for nodes. Each cache policy supports:\\n       `key_func` used to generate a cache key based on the input to a node, which defaults to a `hash` of the input with pickle.\\n       `ttl`, the time to live for the cache in seconds. If not specified, the cache will never expire.\\n\\nFor example: [...] By composing `Nodes` and `Edges`, you can create complex, looping workflows that evolve the state over time. The real power, though, comes from how LangGraph manages that state.To emphasize: `Nodes` and `Edges` are nothing more than functions – they can contain an LLM or just good ol’ code.In short: _nodes do the work, edges tell what to do next_.LangGraph’s underlying graph algorithm uses message passing to define a general program. When a Node completes its operation, it sends messages along one or more edges to other node(s). These recipient nodes then execute their functions, pass the resulting messages to the next set of nodes, and the process continues. Inspired by Google’s Pregel system, the program proceeds in discrete “super-steps.”A super-step can be considered a single',\n",
              "  'score': 0.99989283}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Binding tools**\n",
        "\n",
        "- LLM이 질문에 적합한 Tool을 호출하기\n",
        "\n",
        "- https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/#request-passing-tool-outputs-to-model"
      ],
      "metadata": {
        "id": "Rlddsc8ur_N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\""
      ],
      "metadata": {
        "id": "p-YOXUUfQeVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Passing tool outputs to model\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Adds a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiplies a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "tools = [add, multiply]"
      ],
      "metadata": {
        "id": "5W2-DY5OsJ2t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "o4xWlCCevNin"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
        "\n",
        "llm_with_tools.invoke(query).tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRPsF2IEsQPP",
        "outputId": "aa4f11c4-4d78-4457-c652-9eea6b704eca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'a': 3, 'b': 12},\n",
              "  'id': 'call_Q4o9NOOFlqJ32fGvZrTgNnW1',\n",
              "  'type': 'tool_call'},\n",
              " {'name': 'add',\n",
              "  'args': {'a': 11, 'b': 49},\n",
              "  'id': 'call_B4uFANkK1ZUNLQcjSQtfKNU8',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is 12 % 2?\"\n",
        "\n",
        "llm_with_tools.invoke(query).tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUI1cqPJsOUr",
        "outputId": "2debc3e8-e81d-4014-9b78-6376cec8a861"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuppamOqsOKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Apply to Tavily Search**"
      ],
      "metadata": {
        "id": "8wtFKs8agcg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tools = [tool]\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "llm_with_tools = llm.bind_tools(tools) # TavilySearchResults(tools) 을 호출할 수 있도록 함"
      ],
      "metadata": {
        "id": "LXWvc8RcrrSF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke(\"안녕\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnNhFhMLoMXt",
        "outputId": "7bea4d23-b667-4ec3-acd0-96bc0be26b82"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 81, 'total_tokens': 93, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D5oYQBQH9IOEFXyi6d64qsiDpzeYX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2ccf-cd15-7112-a1fc-1e2d800c3a63-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 81, 'output_tokens': 12, 'total_tokens': 93, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke(\"안녕\").tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvA1MoGD0PXW",
        "outputId": "bc375010-34be-42e3-8310-ed2c7ddc8bea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke(\"What is Langgraph?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX5O_5v1oOxA",
        "outputId": "2810a98c-9e68-42a0-aa8f-01a0a1307662"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 84, 'total_tokens': 103, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D5oYRNOr5XU03wCXcRhHjkiX1yN0J', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c2ccf-d1f9-7e13-b148-462b1265480d-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Langgraph'}, 'id': 'call_DuKbuz6NkPbRYLyKV73clJ8d', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 84, 'output_tokens': 19, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke(\"What is Langgraph?\").tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U15z43Ms1y_",
        "outputId": "8d6c8533-09e7-49d6-8b35-2efce7af130d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'tavily_search_results_json',\n",
              "  'args': {'query': 'Langgraph'},\n",
              "  'id': 'call_OlWAK4ryfUNFXIMxnYEeK6sJ',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langgraph - Web search + LLM = 검색 Chatbot\n",
        "\n",
        "- Tool을 호출하고 그 결과를 모델(LLM)로 전달하기\n",
        "\n",
        "- https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-2-enhancing-the-chatbot-with-tools"
      ],
      "metadata": {
        "id": "pCwkNrcaNwCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Node** - 실제 작업을 수행하는 단위\n",
        "- chatbot, tools"
      ],
      "metadata": {
        "id": "-Q80VucLdbtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**chatbot**"
      ],
      "metadata": {
        "id": "AXS4Izk_du5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict): # 그래프의 상태를 정의하는 클래스\n",
        "    messages: Annotated[list, add_messages] # 메시지 누적\n",
        "\n",
        "graph_builder = StateGraph(State) # StateGraph 생성 (대화 흐름 관리)\n",
        "\n",
        "def chatbot(state: State):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5JahKevI9_F",
        "outputId": "0c0b0fa0-9db5-463a-8be4-6b4cab217706"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9cfe2ca4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tools**"
      ],
      "metadata": {
        "id": "o-xz-aXTdwm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "class BasicToolNode:\n",
        "    \"\"\"\n",
        "        A node that runs the tools requested in the last AIMessage.\n",
        "        마지막 AIMessage에서 요청된 도구를 실행하는 노드\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tools: list) -> None:\n",
        "        self.tools_by_name = {tool.name: tool for tool in tools} # [\"tavily_search_results_json\" : TavilySearchResults()]\n",
        "\n",
        "    def __call__(self, inputs: dict):\n",
        "        if messages := inputs.get(\"messages\", []):\n",
        "            message = messages[-1] # 마지막 message\n",
        "        else:\n",
        "            raise ValueError(\"No message found in input\")\n",
        "        outputs = []\n",
        "        for tool_call in message.tool_calls: # 메시지에서 호출된 도구를 불러옴\n",
        "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke( # Tool 호출 실행\n",
        "                tool_call[\"args\"]\n",
        "            )\n",
        "            outputs.append( # Tool 호출 결과(ToolMessage) 추가\n",
        "                ToolMessage(\n",
        "                    content=json.dumps(tool_result),\n",
        "                    name=tool_call[\"name\"],\n",
        "                    tool_call_id=tool_call[\"id\"],\n",
        "                )\n",
        "            )\n",
        "        return {\"messages\": outputs}\n",
        "\n",
        "tool_node = BasicToolNode(tools=[tool])\n",
        "graph_builder.add_node(\"tools\", tool_node)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPHJlu05KCd6",
        "outputId": "9c7f54a4-08f6-41fa-dbd1-ea6011330b34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9cfe2ca4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Edge** - 노드 간의 연결"
      ],
      "metadata": {
        "id": "86znc3qidpZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**조건부 엣지, 라우팅 (add_conditional_edges)**"
      ],
      "metadata": {
        "id": "Lqq5tR9lk276"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_tools(\n",
        "    state: State,\n",
        "):\n",
        "    \"\"\"\n",
        "    Use in the conditional_edge to route to the ToolNode if the last message\n",
        "    has tool calls. Otherwise, route to the end.\n",
        "    \"\"\"\n",
        "    if isinstance(state, list):\n",
        "        ai_message = state[-1]\n",
        "    elif messages := state.get(\"messages\", []):\n",
        "        ai_message = messages[-1]\n",
        "    else:\n",
        "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
        "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0: # if the last message has \"tool_calls\"\n",
        "        return \"tools\"\n",
        "    return END\n",
        "\n",
        "# 조건부 엣지 연결\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\", # 시작 노드\n",
        "    route_tools,\n",
        "    {\"tools\": \"tools\", END: END}, # 반환값이 \"tools\" 면 \"tools\" 노드로, END 면 END로 이동\n",
        ")"
      ],
      "metadata": {
        "id": "A1bridmtKcRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a88104-7b8e-4505-8a4a-2cdd946f6dd3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d9cfe2ca4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 엣지 연결\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\") # 도구가 호출될 때마다 챗봇으로 돌아가 다음 단계를 결정\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "rKyZ4XrQ80iu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **그래프 시각화**"
      ],
      "metadata": {
        "id": "Ybsyj6O8kJXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "fXzCe94TKfUL",
        "outputId": "08cc9f9b-9563-4245-f8d9-580ca1c75ff4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **실행**"
      ],
      "metadata": {
        "id": "LM0yrjwskNpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}): # graph 노드 호출 결과 받아옴\n",
        "        for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content) # AI 답변 출력"
      ],
      "metadata": {
        "id": "PQpzyrkZLxTD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        stream_graph_updates(user_input)\n",
        "    except:\n",
        "        # fallback if input() is not available\n",
        "        user_input = \"What do you know about LangGraph?\"\n",
        "        print(\"User: \" + user_input)\n",
        "        stream_graph_updates(user_input)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K7sSYQ9KhOA",
        "outputId": "9bf10cb5-803a-4234-a32f-f3b468309ca0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: 안녕\n",
            "Assistant: 안녕하세요! 무엇을 도와드릴까요?\n",
            "User: LangGraph가 뭐야?\n",
            "Assistant: \n",
            "Assistant: [{\"title\": \"LangGraph overview - Docs by LangChain\", \"url\": \"https://docs.langchain.com/oss/python/langgraph/overview\", \"content\": \"Trusted by companies shaping the future of agents\\u2014 including Klarna, Replit, Elastic, and more\\u2014 LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents.LangGraph is very low-level, and focused entirely on agent orchestration. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools.We will commonly use LangChain components throughout the documentation to integrate models and tools, but you don\\u2019t need to use LangChain to use LangGraph. If you are just getting started with agents or want a higher-level abstraction, we recommend you use LangChain\\u2019s agents that provide pre-built architectures for common LLM and tool-calling [...] LangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. LangGraph does not abstract prompts or architecture, and provides the following central benefits:\\n   Durable execution: Build agents that persist through failures and can run for extended periods, resuming from where they left off.\\n   Human-in-the-loop: Incorporate human oversight by inspecting and modifying agent state at any point.\\n   Comprehensive memory: Create stateful agents with both short-term working memory for ongoing reasoning and long-term memory across sessions.\\n   Debugging with LangSmith: Gain deep visibility into complex agent behavior with visualization tools that trace execution paths, capture state transitions, and provide detailed runtime metrics. [...] pre-built architectures for common LLM and tool-calling loops.LangGraph is focused on the underlying capabilities important for agent orchestration: durable execution, streaming, human-in-the-loop, and more.\", \"score\": 0.9999795}, {\"title\": \"What is LangGraph? - IBM\", \"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"# What is LangGraph?\\n\\n## Authors\\n\\nSenior Technology Advocate\\n\\n## LangGraph overview\\n\\nLangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] LangGraph workflow\\n\\nLangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent\\u2019s state. Within LangGraph, the \\u201cstate\\u201d feature serves as a memory bank that records and tracks all the valuable information processed by the AI system. It\\u2019s similar to a digital notebook where the system captures and updates data as it moves through various stages of a workflow or graph analysis. [...] LangGraph is also built on several key technologies, including LangChain, a Python framework for building AI applications. LangChain includes a library for building and managing LLMs. LangGraph also uses the human-in-the-loop approach. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems.\\n\\nDelve deeper into the world of LangGraph by exploring its key features, benefits and use cases. By the end of this article, you will have the knowledge and resources to take the next steps with LangGraph.\\n\\n## Key components of LangGraph\", \"score\": 0.9999683}]\n",
            "Assistant: LangGraph는 LangChain에 의해 개발된 오픈 소스 AI 에이전트 프레임워크로, 복잡한 생성적 AI 에이전트 워크플로우를 구축, 배포 및 관리할 수 있도록 설계되었습니다. LangGraph는 에이전트의 상태를 기록하고 추적하여 AI 시스템이 처리한 정보를 기억하고 업데이트할 수 있는 \"상태\" 기능을 제공합니다.\n",
            "\n",
            "LangGraph의 주요 기능 및 특징은 다음과 같습니다:\n",
            "\n",
            "- **지속 가능한 실행**: 실패를 극복하고 중지된 지점에서 다시 실행할 수 있는 에이전트를 구축할 수 있습니다.\n",
            "- **인간 참여**: 아무 때나 에이전트 상태를 점검하고 수정하는 등 인간이 중간에 개입할 수 있습니다.\n",
            "- **포괄적인 기억장치**: 작업 중인 에이전트에 단기 기억과 장기 기억을 모두 제공하여 에이전트가 얻은 정보를 관리합니다.\n",
            "- **LangSmith를 통한 디버깅**: 에이전트 동작 경로를 추적하고 상태 전환을 포착하는 등 복잡한 에이전트 동작을 깊이 있게 파악할 수 있는 도구를 제공합니다.\n",
            "\n",
            "LangGraph는 주로 AI 워크플로우의 복잡한 관계를 모델링하고 관리하는 데 사용됩니다. 다양한 AI 응용 프로그램을 개발하기 위한 다재다능한 플랫폼을 사용자에게 제공합니다.\n",
            "\n",
            "추가 정보를 원하시면, [LangGraph 문서](https://docs.langchain.com/oss/python/langgraph/overview) 또는 [IBM의 LangGraph 개요](https://www.ibm.com/think/topics/langgraph) 페이지를 참고하세요.\n",
            "User: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8g4XLzXKrm4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}